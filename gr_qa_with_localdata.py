import os
import gradio as gr
import requests
from typing import List
import pdfminer.high_level as pdfminer
from docx import Document
from openai import OpenAI

import json
import shutil
import logging
import uuid



LOG_FORMAT = "%(levelname) -5s %(asctime)s" "-1d: %(message)s"
logger = logging.getLogger()
logger.setLevel(logging.INFO)
logging.basicConfig(format=LOG_FORMAT)


UPLOAD_ROOT_PATH = os.path.join(os.path.dirname(__file__), "content")

global selected_file_path
selected_file_path = ""

webui_title = """
# ðŸŽ‰äº§å“å’¨è¯¢ðŸŽ‰

"""
init_message = f"""æ¬¢è¿Žä½¿ç”¨ äº§å“å’¨è¯¢ï¼

è¯·åœ¨å³ä¾§ä¸Šä¼ æ–‡ä»¶ï¼Œç›®å‰æ”¯æŒä¸Šä¼ pdf,docx,txtç±»åž‹æ–‡ä»¶ã€‚
"""



def get_f_list():
    lst_default = ["è¿˜æœªä¸Šä¼ è¿‡æ–‡ä»¶"]
    if not os.path.exists(UPLOAD_ROOT_PATH):
        return lst_default
    lst = os.listdir(UPLOAD_ROOT_PATH)
    if not lst:
        return lst_default
    lst.sort()
    return [""] + lst


f_list = get_f_list()
logger.info(f"f_list:{f_list}")

history : List = None



def predict_long(prompt:str,history:List=None):
    url = "you llm api url"
    post_data = {"prompt":prompt,"history":history}
    params = {}
    response = requests.post(url, json=post_data, params=params, timeout=200)
    
    if response.status_code == 200:
        result = json.loads(response.content)
        logger.info("answer finish")
        return result
    else:
        return {"error": "Prediction failed"}



# å¯åŠ¨Gradioåº”ç”¨å‰çš„å‡†å¤‡å·¥ä½œ
def process_file(file):
    # æ ¹æ®æ–‡ä»¶ç±»åž‹é€‰æ‹©é€‚å½“çš„è§£æžæ–¹æ³•ï¼Œè¿™é‡Œæ”¯æŒPDFã€docxå’Œtxtæ–‡ä»¶
    if file.endswith(".pdf"):
        # è§£æžPDFæ–‡ä»¶
        # è¿™é‡Œä½ å¯ä»¥ä½¿ç”¨é€‚å½“çš„PDFè§£æžåº“ï¼Œæ¯”å¦‚PyMuPDFæˆ–pdfplumber
        parsed_text  = pdfminer.extract_text(file)
    elif file.endswith(".docx"):
        # è§£æždocxæ–‡ä»¶
        # è¿™é‡Œä½ å¯ä»¥ä½¿ç”¨python-docxåº“ç­‰
        doc = Document(file)
        parsed_text = ''.join(paragraph.text for paragraph in doc.paragraphs)
        
    elif file.endswith(".txt"):
        # ç›´æŽ¥è¯»å–txtæ–‡ä»¶
        with open(file,"r",encoding="utf-8") as f:
            parsed_text = f.read()
    else:
        # å…¶ä»–æ–‡ä»¶ç±»åž‹çš„å¤„ç†æ–¹å¼ï¼Œæ ¹æ®å®žé™…éœ€æ±‚è¿›è¡Œè°ƒæ•´
        return "Unsupported file type"
    return parsed_text[:20000]

def get_answer_shot(query,file_path,Chatbot):
    contents = []
    for file in file_path:
        file_content = process_file(file)
        contents.append(file_content)
    all_contents = "#".join(contents)
    prompt = f"çŽ°åœ¨æˆ‘å°†ç»™ä½ ä¸€ä»½æ–‡æ¡£ï¼Œæˆ‘ä¼šè¯¢é—®å’Œè¿™ç¯‡æ–‡æ¡£ç›¸å…³çš„é—®é¢˜ã€‚query:{query}ï¼Œæ–‡æ¡£å†…å®¹ä¸ºï¼š{all_contents}"
    result_3 = client_api(prompt)
    return Chatbot+[[None,result_3]] , ""

def limit_historys(historys):
    if len(historys)>8:
        historys_new = historys[-4:]
        historys_new.insert(0,historys[0])
        # print(len(historys_new))
        return historys_new
    else:
        return historys

def get_answer_long(query,file_path,chatbot,history):
    global selected_file_path
    selected_file_path = ""
    
    # logger.info(f"file_path:{file_path}")
    if file_path == UPLOAD_ROOT_PATH:
        answer = "è¯·å…ˆæ·»åŠ æ–‡ä»¶"
        return chatbot+[[query,answer]],"",None
    contents = []
    for file in file_path:
        file_content = process_file(file)
        contents.append(file_content)
    all_contents = "#".join(contents)

    if file_path != selected_file_path:
        history = None
        selected_file_path = file_path
    
    if history is None:
        logger.info(f"è¾“å…¥å¤§æ¨¡åž‹æ–‡æ¡£ï¼š{os.path.split(file_path[0])[-1]}")
        prompt = f"çŽ°åœ¨æˆ‘å°†ç»™ä½ ä¸€ä»½æ–‡æ¡£ï¼Œæˆ‘ä¼šè¯¢é—®å’Œè¿™ç¯‡æ–‡æ¡£ç›¸å…³çš„é—®é¢˜ã€‚æ–‡æ¡£å†…å®¹ä¸º:{all_contents}"
        logger.info(f"prompt string len:{len(prompt)}")
        result = predict_long(prompt,history)
        history = limit_historys(result["history"])



    logger.info(f"history len:{len(history)}")
    logger.info(f"user:{query}")
    result_out = predict_long(query,history)
    answer = result_out["response"]
    history = limit_historys(result_out["history"])
    return chatbot+[[query,answer]],"",history



def change_file_name_input(select_file,chatbot):
    select_path = os.path.join(UPLOAD_ROOT_PATH,select_file)
    file_status = f"å·²ç»é€‰æ‹©:{select_file}"
    logger.info(f"select file:{select_file}")
    logger.info(f"select path:{select_path}")
    return [select_path],  chatbot+[[None,file_status]]



def get_file_store(files,chatbot,f_list):
    filelist = []
    if not os.path.exists(os.path.join(UPLOAD_ROOT_PATH)):
        os.makedirs(os.path.join(UPLOAD_ROOT_PATH))
    add_file = []
    for file in files:
        filename = os.path.split(file.name)[-1]
        add_file.append(filename)
        shutil.move(file.name, os.path.join(UPLOAD_ROOT_PATH, filename))
        filelist.append(os.path.join(UPLOAD_ROOT_PATH, filename))
    logger.info(filelist)
    file_status = f"å·²ä¸Šä¼ {'ã€'.join(os.path.split(file)[-1] for file in files)}"
    return gr.update(visible=True,choices=add_file+f_list, value=add_file[0]), filelist, chatbot+[[None,file_status]]



block_css = """.importantButton {
    background: linear-gradient(45deg, #7e0570,#5d1c99, #6e00ff) !important;
    border: none !important;
}
.importantButton:hover {
    background: linear-gradient(45deg, #ff00e0,#8500ff, #6e00ff) !important;
    border: none !important;
}"""


with gr.Blocks(css=block_css) as demo:
    file_path, file_status, f_list, history = gr.State(UPLOAD_ROOT_PATH), gr.State(""),  gr.State(f_list), gr.State(history)


    gr.Markdown(webui_title)
    with gr.Tab("å¯¹è¯"):
        with gr.Row():
            with gr.Column(scale=10):
                chatbot = gr.Chatbot([[None, init_message],],
                                        elem_id="chat-box",
                                        show_label=False)
                query = gr.Textbox(show_label=False,
                                    placeholder="è¯·è¾“å…¥æé—®å†…å®¹ï¼ŒæŒ‰å›žè½¦è¿›è¡Œæäº¤")
            with gr.Column(scale=5):
                gr.Markdown("æ·»åŠ æ–‡ä»¶")
                with gr.Row():
                    with gr.Tab("ä¸Šä¼ æ–‡ä»¶"):
                        files = gr.File(label="æ·»åŠ æ–‡ä»¶",
                                        file_types=['.txt', '.docx', '.pdf'],
                                        file_count="multiple",
                                        show_label=False
                                        )
                        load_file_button = gr.Button("ä¸Šä¼ æ–‡ä»¶")

                    with gr.Tab("é€‰æ‹©æ–‡ä»¶"):
                         select_file = gr.Dropdown(f_list.value,
                                            label="è¯·é€‰æ‹©è¦è§£æžçš„æ–‡ä»¶",
                                            interactive=True,
                                            value=f_list.value[0] if len(f_list.value) > 1 else None)

                    
            load_file_button.click(get_file_store,
                                    show_progress=True,
                                    inputs=[files,chatbot,f_list],
                                    outputs=[select_file,file_path,chatbot]
                                    )
            
            select_file.change(fn=change_file_name_input,
                               inputs=[select_file,chatbot],
                               outputs=[file_path,chatbot])
            
           
            
            query.submit(fn=get_answer_long,
                            inputs=[query,file_path,chatbot,history],
                            outputs=[chatbot,query,history])
                    

                    


# demo.queue(concurrency_count=3)
demo.launch(server_name='0.0.0.0',
        server_port=8000,
        show_api=False,
        share=True,
        inbrowser=False)